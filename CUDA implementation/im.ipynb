{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93632e50",
   "metadata": {},
   "source": [
    "# CUDA Enabled CNN from Scratch\n",
    "This notebook uses Cupy to run the CNN on a CUDA-enabled GPU. Make sure Cupy is installed in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b805034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MNIST from OpenML...\n",
      "MNIST CNN initialized!\n",
      "MNIST CNN initialized!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MaxPool2' object has no attribute 'last_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     72\u001b[0m   num_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 74\u001b[0m l, acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l\n\u001b[0;32m     76\u001b[0m num_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "Cell \u001b[1;32mIn[3], line 55\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(im, label, lr)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Backprop through softmax, maxpool, and conv layers\u001b[39;00m\n\u001b[0;32m     54\u001b[0m gradient \u001b[38;5;241m=\u001b[39m softmax\u001b[38;5;241m.\u001b[39mbackprop(gradient, lr)\n\u001b[1;32m---> 55\u001b[0m gradient \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m conv\u001b[38;5;241m.\u001b[39mbackprop(gradient, lr)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, acc\n",
      "File \u001b[1;32mc:\\GitHub\\CNN-from-scratch\\maxpoolCUDA.py:46\u001b[0m, in \u001b[0;36mMaxPool2.backprop\u001b[1;34m(self, d_L_d_out)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbackprop\u001b[39m(\u001b[38;5;28mself\u001b[39m, d_L_d_out):\n\u001b[0;32m     44\u001b[0m   \u001b[38;5;66;03m# Vectorized backprop for 2x2 maxpool layer\u001b[39;00m\n\u001b[0;32m     45\u001b[0m   \u001b[38;5;66;03m# Assume self.last_input was saved during forward pass.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m   h, w, f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_input\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     47\u001b[0m   new_h, new_w \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, w \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     48\u001b[0m   \u001b[38;5;66;03m# reshape input to (new_h, 2, new_w, 2, f)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MaxPool2' object has no attribute 'last_input'"
     ]
    }
   ],
   "source": [
    "import cupy as np\n",
    "from convCUDA import Conv3x3\n",
    "from maxpoolCUDA import MaxPool2\n",
    "from softmaxCUDA import Softmax\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load MNIST from OpenML\n",
    "print(\"Downloading MNIST from OpenML...\")\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "images = mnist.data.values.reshape(-1, 28, 28).astype(np.uint8)\n",
    "images = np.asarray(images)  # Convert images to Cupy array\n",
    "labels = mnist.target.astype(int).values  # ensure labels are integers\n",
    "\n",
    "test_images = images[:10000]\n",
    "test_labels = labels[:10000]\n",
    "train_images = images[10000:]\n",
    "train_labels = labels[10000:]\n",
    "\n",
    "conv = Conv3x3(8)                  # 28x28x1 -> 26x26x8\n",
    "pool = MaxPool2()                  # 26x26x8 -> 13x13x8\n",
    "softmax = Softmax(13 * 13 * 8, 10)   # 13x13x8 -> 10\n",
    "\n",
    "def forward(image, label):\n",
    "    '''\n",
    "    Completes a forward pass of the CNN and calculates the accuracy and\n",
    "    cross-entropy loss.\n",
    "    - image is a 2d numpy array\n",
    "    - label is a digit\n",
    "    '''\n",
    "    out = conv.forward((image / 255) - 0.5)\n",
    "    out = pool.forward(out)\n",
    "    out = softmax.forward(out)\n",
    "\n",
    "    loss = -np.log(out[label])\n",
    "    acc = 1 if np.argmax(out) == label else 0\n",
    "\n",
    "    return out, loss, acc\n",
    "\n",
    "def train(im, label, lr=.005):\n",
    "  '''\n",
    "  Completes a full training step on the given image and label.\n",
    "  Returns the cross-entropy loss and accuracy.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  - lr is the learning rate\n",
    "  '''\n",
    "  out, loss, acc = forward(im, label)\n",
    "\n",
    "  # Calculate initial gradient\n",
    "  gradient = np.zeros(10)\n",
    "  gradient[label] = -1 / out[label]\n",
    "\n",
    "  # Backprop through softmax, maxpool, and conv layers\n",
    "  gradient = softmax.backprop(gradient, lr)\n",
    "  gradient = pool.backprop(gradient)\n",
    "  conv.backprop(gradient, lr)\n",
    "\n",
    "  return loss, acc\n",
    "\n",
    "print('MNIST CNN initialized!')\n",
    "\n",
    "# Train!\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "  if i % 100 == 99:\n",
    "    print(\n",
    "      '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\n",
    "      (i + 1, loss / 100, num_correct)\n",
    "    )\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "\n",
    "  l, acc = train(im, label)\n",
    "  loss += l\n",
    "  num_correct += acc\n",
    "\n",
    "# Parallel mini-batch training\n",
    "batch_size = 64\n",
    "num_batches = train_images.shape[0] // batch_size\n",
    "loss_total = 0\n",
    "correct_total = 0\n",
    "for b in range(num_batches):\n",
    "    batch_imgs = train_images[b*batch_size:(b+1)*batch_size]  # shape (N, 28, 28)\n",
    "    batch_labels = train_labels[b*batch_size:(b+1)*batch_size]  # added extraction of labels\n",
    "    # Vectorized forward pass:\n",
    "    conv_out = conv.forward_batch(batch_imgs)  # shape (N, 26, 26, num_filters)\n",
    "    pool_out = pool.forward_batch(conv_out)      # shape (N, 13, 13, num_filters)\n",
    "    # Flatten for softmax:\n",
    "    N = pool_out.shape[0]\n",
    "    flat = pool_out.reshape(N, -1)\n",
    "    softmax_out = softmax.forward_batch(flat)      # shape (N, 10)\n",
    "    # Compute cross-entropy loss & accuracy vectorized:\n",
    "    one_hot = np.zeros_like(softmax_out)\n",
    "    one_hot[np.arange(N), batch_labels] = 1\n",
    "    loss = -np.sum(one_hot * np.log(softmax_out + 1e-7)) / N\n",
    "    pred_labels = np.argmax(softmax_out, axis=1)\n",
    "    acc = np.mean(pred_labels == batch_labels) * 100\n",
    "    loss_total += loss\n",
    "    correct_total += acc\n",
    "    if (b+1) % 10 == 0:\n",
    "        print(f'Batch {(b+1)} / {num_batches}: Loss = {loss:.3f}, Accuracy = {acc:.1f}%')\n",
    "\n",
    "# Synchronize GPU streams to ensure all parallel computations are complete\n",
    "np.cuda.Device().synchronize()\n",
    "\n",
    "# Test the CNN\n",
    "print('\\n--- Testing the CNN ---')\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(test_images, test_labels):\n",
    "  _, l, acc = forward(im, label)\n",
    "  loss += l\n",
    "  num_correct += acc\n",
    "\n",
    "num_tests = len(test_images)\n",
    "print('Test Loss:', loss / num_tests)\n",
    "print('Test Accuracy:', num_correct / num_tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
